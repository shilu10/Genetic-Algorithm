{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T11:54:12.525666Z",
     "iopub.status.busy": "2023-03-22T11:54:12.525169Z",
     "iopub.status.idle": "2023-03-22T11:54:12.534396Z",
     "shell.execute_reply": "2023-03-22T11:54:12.533373Z",
     "shell.execute_reply.started": "2023-03-22T11:54:12.525635Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "class GenPopulation:\n",
    "    def __init__(self): \n",
    "        self.population = []\n",
    "\n",
    "    def generate(self, num_features: int, max_pop_size: int, max_features=0, verbose=False) -> np.array: \n",
    "        \"\"\"\n",
    "            Params: \n",
    "                number_of_features: is used to encode the actual data into genotype.\n",
    "                max_pop_size:       is used to restrict number of individual generation.\n",
    "                max_featrures:      how many features needed to be in the subset. \n",
    "                                      if max_features is 0, then maximum subset size is number of number \n",
    "        \"\"\"\n",
    "        \n",
    "        for _ in range(max_pop_size):\n",
    "            individual = ''\n",
    "            for col in range(num_features):\n",
    "                if individual.count('1') == max_features:\n",
    "                    individual += '0'\n",
    "                    continue\n",
    "\n",
    "                individual += str(random.randint(0, 1))\n",
    "\n",
    "            if verbose: print(f'Genrated a new indivudal: {individual}')\n",
    "            self.population.append(individual)\n",
    "            \n",
    "        if verbose: print(f'Generated list of {num_individuals} individuals: {individuals}')\n",
    "        self.population = [self.population[i] for i in range(len(self.population)) if self.population[i] not in self.population[i+1: ]]\n",
    "        return np.array(self.population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '00', '01'], dtype='<U2')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = GenPopulation()\n",
    "\n",
    "g.generate(2, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T11:54:12.554795Z",
     "iopub.status.busy": "2023-03-22T11:54:12.554523Z",
     "iopub.status.idle": "2023-03-22T11:54:22.101577Z",
     "shell.execute_reply": "2023-03-22T11:54:22.099903Z",
     "shell.execute_reply.started": "2023-03-22T11:54:12.554769Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras  \n",
    "\n",
    "\n",
    "class ANN(keras.Model): \n",
    "    \"\"\"\n",
    "        SubClassing way of building the Keras Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, fc1, fc2, fc3, in_dims, out_dims): \n",
    "        super(ANN, self).__init__()\n",
    "        \n",
    "        #self.input = Input(input_shape=(in_dims, ))\n",
    "        self.out_dims = out_dims\n",
    "        self.fc1 = Dense(fc1,  activation=\"relu\", input_shape=(in_dims, ))\n",
    "        self.fc2 = Dense(fc1,  activation=\"relu\")\n",
    "        self.fc3 = Dense(fc1,  activation=\"relu\")\n",
    "\n",
    "        self.output_sigmoid = Dense(out_dims, activation=\"sigmoid\")\n",
    "        self.output_softmax = Dense(out_dims, activation=\"softmax\")\n",
    "    \n",
    "    def call(self, input_): \n",
    "     #   x = self.input(input)\n",
    "        x = self.fc1(input_)\n",
    "      #  x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        if self.out_dims > 1: \n",
    "            x = self.output_softmax(x)\n",
    "            return x \n",
    "        \n",
    "        x = self.output_sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T11:54:22.106887Z",
     "iopub.status.busy": "2023-03-22T11:54:22.104145Z",
     "iopub.status.idle": "2023-03-22T11:54:22.571365Z",
     "shell.execute_reply": "2023-03-22T11:54:22.570266Z",
     "shell.execute_reply.started": "2023-03-22T11:54:22.106835Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.metrics import *\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def get_metrics_value(y_true, y_pred, regression): \n",
    "    \"\"\"\n",
    "        this function is used to calculate the different metrics score for both regression and classification.\n",
    "        Params:\n",
    "            y_true: test y value.\n",
    "            y_pred: prediction for test x from model.\n",
    "            regression: bool value to represent whether it is regression problem or not.\n",
    "    \"\"\"\n",
    "    if regression: \n",
    "        rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "        adj_r2 = r2_score(y_true, y_pred)\n",
    "        return rmse, adj_r2\n",
    "    \n",
    "    else: \n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T12:23:52.484681Z",
     "iopub.status.busy": "2023-03-22T12:23:52.484135Z",
     "iopub.status.idle": "2023-03-22T12:23:52.506614Z",
     "shell.execute_reply": "2023-03-22T12:23:52.505449Z",
     "shell.execute_reply.started": "2023-03-22T12:23:52.484645Z"
    }
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np \n",
    "import sklearn\n",
    "#from metrics import *\n",
    "#from neural_net import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf \n",
    "import math \n",
    "\n",
    "class FitnessFunction: \n",
    "    def __init__(self, population, train_X, train_y, test_X, test_y, feature_names, scoring_criteria): \n",
    "        '''\n",
    "            Params:\n",
    "                population: Population array from generate_pop method.\n",
    "                model: Model from build model method.\n",
    "                train_X, train_y: training data for our model.\n",
    "                test_X, test_y: testing data for our model.\n",
    "                scoring_criteria: On what basis scoring, needs to happend eg: Accuracy, f1-score, recall, precision.\n",
    "        '''\n",
    "\n",
    "        self.population = population\n",
    "        self.scores = []\n",
    "        self.train_X = train_X \n",
    "        self.train_y = train_y\n",
    "        self.test_X = test_X \n",
    "        self.test_y = test_y\n",
    "        self.scoring_criteria = scoring_criteria\n",
    "        self.feature_names = feature_names\n",
    "    \n",
    "    def compile_model(self, fc1, fc2, fc3, input_dims, out_dims): \n",
    "        \"\"\"\n",
    "            This method is used to compile the neural network model using adam and binary crossentropy.\n",
    "            Params:\n",
    "                fc1          : Number of hidden unit for fully connected layer 1.\n",
    "                fc2          : Number of hidden unit for fully connected layer 2.\n",
    "                fc3          : Number of hidden unit for fully connected layer 3.\n",
    "                input_dims   : Input Dimension of the Neural Network model, which number of features in the dataset.\n",
    "                out_dims     : Output Dimension of the Neural Network model, by default it is 1.\n",
    "        \"\"\"\n",
    "        model = ANN(fc1, fc2, fc3, input_dims, out_dims)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss=\"binary_crossentropy\")\n",
    "        return model\n",
    "\n",
    "    def convert_to_nparray(self, individual): \n",
    "        \"\"\"\n",
    "            This method, will convert the data of type pandas dataframe into numpy array, to train a tensorflow model.\n",
    "            Params: \n",
    "                genotype     : Genotype is the encoding of the features(individual in population).\n",
    "        \"\"\"\n",
    "        col_numbers = [_ for _ in range(len(individual)) if individual[_] == 1]\n",
    "        col_names = [self.feature_names[i] for i in range(len(self.feature_names)) if i in col_numbers]\n",
    "        \n",
    "        train_X = np.asarray(self.train_X[col_names])\n",
    "        train_y = np.asarray(self.train_y)\n",
    "        test_X = np.asarray(self.test_X[col_names])\n",
    "        test_y = np.asarray(self.test_y)\n",
    "        return train_X, train_y, test_X, test_y\n",
    "\n",
    "    def train_model(self, train_X, train_y, input_dims):\n",
    "        \"\"\"\n",
    "            This method, will train a neural net model, with the specific individual.\n",
    "            Params:\n",
    "                train_X       : Independent variable to the model.\n",
    "                train_y       : Dependent variable to the model.\n",
    "                input_dims    : Input dimension of the model, len(individual).\n",
    "        \"\"\"\n",
    "        model = self.compile_model(32, 16, 16, input_dims, 1)\n",
    "        model.fit(train_X, train_y, epochs=10, verbose=False)\n",
    "        col_numbers = []\n",
    "        return model\n",
    "\n",
    "    def test_model(self, model, test_X, train_X): \n",
    "        \"\"\"\n",
    "            This method, will return a prediction for the prediction data.\n",
    "            Params:\n",
    "                test_X        : Independent Variable of testing data.\n",
    "                model         : fitted model returned by the train_model method.\n",
    "                train_X       : Independent Variable of training data.\n",
    "        \"\"\"\n",
    "        pred_y = model.predict(test_X, verbose=False)\n",
    "        pred_train_y = model.predict(train_X, verbose=False)\n",
    "        pred_y = np.where(pred_y >= 0.5, 1, 0)\n",
    "        return pred_y\n",
    "    \n",
    "    def get_metrics_score(self, y_true, y_pred, regression): \n",
    "        \"\"\"\n",
    "            This method, will calculate the metrics value for the prediction done by the model.\n",
    "            Params: \n",
    "                y_true        : Ground Truth value of the testing data.\n",
    "                y_pred        : Prediction data of the model.\n",
    "                regression    : To specify, whether it is regression task or classfication task.\n",
    "        \"\"\"\n",
    "        results = get_metrics_value(y_true, y_pred, regression)\n",
    "\n",
    "        if not regression:\n",
    "            acc, precision, recall, f1_score = results \n",
    "            return acc\n",
    "\n",
    "        else: rmse, adj_r2 = results\n",
    "\n",
    "        if self.scoring_criteria == \"rmse\" and regression: \n",
    "            return ((0.9 * rmse) + (0.10 * adj_r2) )\n",
    "\n",
    "        if self.scoring_criteria == \"adj_r2\" and regression: \n",
    "            return ((0.9 * adj_r2) + (0.1 * rmse))\n",
    "\n",
    "        if self.scoring_criteria == \"acc\": \n",
    "            return ((0.88 * acc) + (0.03 * recall) + (0.03 * precision) + (0.03 * f1_score))\n",
    "        \n",
    "        if self.scoring_criteria == \"recall\": \n",
    "            return ((0.03 * acc) + (0.88 * recall) + (0.03 * precision) + (0.03 * f1_score))\n",
    "        \n",
    "        if self.scoring_criteria == \"precision\": \n",
    "            return ((0.03 * acc) + (0.03 * recall) + (0.88 * precision) + (0.03 * f1_score))\n",
    "\n",
    "        if self.scoring_criteria == \"f1\": \n",
    "            return ((0.03 * acc) + (0.03 * recall) + (0.03 * precision) + (0.88 * f1_score))\n",
    "        \n",
    "\n",
    "    def get_fitness_score(self, regression, verbose=True): \n",
    "        \"\"\"\n",
    "            This method calculates the fitness score.\n",
    "            Params:\n",
    "                regression       : To specify, whether it is regression task or classfication task.\n",
    "        \"\"\"\n",
    "        for i, individual in enumerate(self.population):\n",
    "            if np.any(individual): \n",
    "                train_X, train_y, test_X, test_y = self.convert_to_nparray(individual)\n",
    "                model = self.train_model(train_X, train_y, len(individual))\n",
    "                y_pred = self.test_model(model, test_X, train_X)\n",
    "                score = self.get_metrics_score(test_y, y_pred, regression)\n",
    "\n",
    "                score = round(score, 5)\n",
    "                print(f\"[+] Successfully calculated fitness score for individual: {i}\")\n",
    "                self.scores.append(score)\n",
    "\n",
    "        return self.scores / sum(self.scores), self.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T11:54:22.619363Z",
     "iopub.status.busy": "2023-03-22T11:54:22.616615Z",
     "iopub.status.idle": "2023-03-22T11:54:23.409461Z",
     "shell.execute_reply": "2023-03-22T11:54:23.403668Z",
     "shell.execute_reply.started": "2023-03-22T11:54:22.619325Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "import imblearn\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess_dataframe(df): \n",
    "    \"\"\"\n",
    "        This Function, will be used to drop unwanted cols, and it converts the categorical data into numerical.\n",
    "        Params:\n",
    "            df: dataframe object that needed to be processed\n",
    "    \"\"\"\n",
    "    df.drop([\"customerID\"], inplace=True, axis=1)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df.Churn)\n",
    "    churn = le.transform(df.Churn)\n",
    "    df.Churn = churn\n",
    "    \n",
    "    df[df.TotalCharges == \" \"] = 0\n",
    "    df.TotalCharges = df.TotalCharges.apply(lambda x: float(x))\n",
    "    df.MonthlyCharges = df.MonthlyCharges.astype(\"float\")\n",
    "    df = pd.get_dummies(df)\n",
    "    return df\n",
    "\n",
    "def handle_imbalance(train_X, train_y): \n",
    "    \"\"\"\n",
    "        This function, does handle a imbalance data, by doing the oversampling using ADASYN method from imblearn.\n",
    "        Params:\n",
    "            train_X: training x, that needed to be resampled.\n",
    "            train_y: training y, that is of train x\n",
    "    \"\"\"\n",
    "    ada = ADASYN(random_state=42)\n",
    "    train_X, train_y = ada.fit_resample(train_X, train_y)\n",
    "    return train_X, train_y\n",
    "\n",
    "def get_training_testing_data(dataframe, out_col, train_size): \n",
    "    \"\"\"\n",
    "        Params:\n",
    "            dataframe: datafram, that needed to be processed.\n",
    "            out_col: output column for the y(label).\n",
    "            test_split: split size.\n",
    "    \"\"\"\n",
    "    y = dataframe[out_col]\n",
    "    dataframe.drop([out_col], inplace=True, axis=1)\n",
    "    X = dataframe\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=train_size, stratify=y)\n",
    "    train_y = train_y.astype(\"int\")\n",
    "    test_y = test_y.astype(\"int\")\n",
    "\n",
    "    return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T11:54:23.411085Z",
     "iopub.status.busy": "2023-03-22T11:54:23.410699Z",
     "iopub.status.idle": "2023-03-22T11:54:23.434597Z",
     "shell.execute_reply": "2023-03-22T11:54:23.433433Z",
     "shell.execute_reply.started": "2023-03-22T11:54:23.411038Z"
    }
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "\n",
    "def get_next_generation_population(population, fitness_score, mutation_rate): \n",
    "    \"\"\"\n",
    "        This function used to generate a new individauls by combining genes of the parensts from old population.\n",
    "        Params:\n",
    "            population      : Array of individuals created from GenPopulation Class.\n",
    "            fitness_score   : Score calculated for each individual in the population by the fitness class.\n",
    "            mutation_rate   : Amount of mutation needed to be done.\n",
    "    \"\"\"\n",
    "    new_generation_population = []\n",
    "    while len(new_generation_population) <= len(population)-1: \n",
    "        parent_1, parent_2 = pick_parents(population, fitness_score)\n",
    "        child_1, child_2 = reproduce(parent_1, parent_2)\n",
    "        mutated_child1 = mutate(child_1, mutation_rate)\n",
    "        mutated_child2 = mutate(child_2, mutation_rate)\n",
    "        \n",
    "        new_generation_population.append(mutated_child1)\n",
    "        new_generation_population.append(mutated_child2)\n",
    "    \n",
    "    print(\"[+] Successfully generated population for new generation.\")\n",
    "    return new_generation_population\n",
    "    \n",
    "    \n",
    "def pick_parents(population, fitness_score): \n",
    "    \"\"\"\n",
    "        This function, will pick two parent chromosomes from the population.\n",
    "        Params:\n",
    "            population      : Array of individuals created from GenPopulation Class.\n",
    "            fitness_score   : Score calculated for each individual in the population by the fitness class.\n",
    "    \"\"\"\n",
    "    parent_1, parent_2 = random.choices(population, fitness_score, k=2)\n",
    "    return parent_1, parent_2\n",
    "        \n",
    "    \n",
    "def reproduce(parent_1, parent_2):\n",
    "    \"\"\"\n",
    "        This function will generate a new childrens by combining two parents gene.\n",
    "        Params:\n",
    "            parent_1       : parent_1 array that is picked by the pick_parent function.\n",
    "            parent_2       : parent_2 array that is picked by the pick_parent function.\n",
    "    \"\"\"\n",
    "    chromosome_breakage_point = random.randint(1, len(parent_1)-1) \n",
    "    child_1 = parent_1[:chromosome_breakage_point] + parent_2[chromosome_breakage_point:]\n",
    "    child_2 = parent_2[:chromosome_breakage_point], parent_1[chromosome_breakage_point:]\n",
    "    return child_1, child_2\n",
    "\n",
    "\n",
    "def mutate(individual, mutation_rate):\n",
    "    \"\"\"\n",
    "        This function is used to mutate the childrens based randomly.\n",
    "        Params:\n",
    "            mutation_rate     : It is probability value, that decides whether to mutate or not.\n",
    "    \"\"\"\n",
    "    random_index = random.randint(0, len(individual)-1)\n",
    "    \n",
    "    if random.random() < mutation_rate: \n",
    "        random_index_val = individual[random_index]\n",
    "        inverse_random_index_val = int(not random_index_val)\n",
    "        individual[: random_index] + inverse_random_index_val + individual[random_index+1: ]\n",
    "        \n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T12:24:18.278305Z",
     "iopub.status.busy": "2023-03-22T12:24:18.277484Z",
     "iopub.status.idle": "2023-03-22T14:53:56.494605Z",
     "shell.execute_reply": "2023-03-22T14:53:56.493158Z",
     "shell.execute_reply.started": "2023-03-22T12:24:18.278258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Resampling (5634, 60)\n",
      "After Resampling (8318, 60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 0 0 0 0] [0 1 0 0 1 1 0 1 1 0] parents\n",
      "[1 0 0 0 0 1 0 0 1 1] [1 0 1 0 0 1 1 1 1 1] parents\n",
      "[0 1 0 1 0 1 0 0 1 1] [0 1 0 1 0 1 0 0 1 1] parents\n",
      "[1 0 1 0 1 1 1 0 1 1] [1 1 0 1 0 0 1 0 1 1] parents\n",
      "[1 1 1 0 0 1 1 1 1 0] [1 1 0 1 0 0 1 0 1 1] parents\n",
      "[0 1 0 1 0 1 0 0 1 1] [0 1 1 1 1 0 0 0 0 1] parents\n",
      "[0 1 1 0 0 0 0 0 0 0] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[1 0 0 0 0 1 0 0 0 1] [1 0 0 1 1 1 1 1 1 0] parents\n",
      "[1 0 1 0 0 1 1 1 1 1] [1 1 1 0 1 1 0 0 0 0] parents\n",
      "[1 0 0 1 1 1 1 1 1 0] [0 0 0 0 0 0 1 1 0 1] parents\n",
      "[1 0 0 1 0 1 1 1 0 0] [1 1 1 1 0 1 0 1 0 0] parents\n",
      "[1 1 1 0 0 0 0 1 1 0] [0 1 0 1 0 0 0 1 0 1] parents\n",
      "[1 1 0 1 1 1 1 0 0 0] [0 0 1 0 1 0 0 0 0 0] parents\n",
      "[0 1 0 0 0 0 1 0 1 0] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[0 1 0 1 1 0 1 0 0 1] [1 1 1 0 0 1 1 1 1 0] parents\n",
      "[1 1 0 1 0 1 0 0 1 1] [1 0 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 1 1 1 0 0 1 0 0] [1 0 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 0 1 0 1 0 0 1 1] [0 1 0 1 1 0 1 0 0 1] parents\n",
      "[0 1 1 1 1 0 0 0 0 1] [0 1 0 0 0 0 1 0 1 0] parents\n",
      "[1 0 0 0 0 1 0 0 0 1] [1 1 1 0 0 1 1 0 0 0] parents\n",
      "[0 0 0 0 0 0 1 1 0 1] [0 1 1 0 1 0 1 0 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 0] [1 1 1 0 0 1 1 1 0 1] parents\n",
      "[1 1 0 1 1 1 1 0 0 0] [0 1 0 0 0 0 1 0 1 0] parents\n",
      "[0 0 1 1 0 1 1 1 0 1] [1 0 0 0 0 1 0 0 0 1] parents\n",
      "[0 1 0 0 0 0 1 0 1 0] [1 1 0 0 0 0 1 1 0 1] parents\n",
      "Generation: 0, Max Fitness Score: 0.74869\n",
      "[1 1 1 0 0 1 1 1 1 1] [1 0 0 0 1 1 1 1 1 0] parents\n",
      "[0 1 0 1 0 1 0 0 1 1] [1 0 1 0 0 1 1 1 1 1] parents\n",
      "[0 0 0 0 0 0 1 1 0 0] [1 1 1 0 0 0 1 0 0 1] parents\n",
      "[1 0 0 0 0 0 1 1 0 1] [1 0 1 0 0 1 1 1 1 1] parents\n",
      "[0 1 0 1 0 1 1 0 0 1] [0 1 1 1 0 1 1 0 0 1] parents\n",
      "[1 0 0 0 0 1 0 0 0 0] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 1] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[1 1 1 1 0 1 0 1 0 0] [0 1 0 1 1 0 1 0 0 1] parents\n",
      "[1 1 0 1 0 0 1 0 1 0] [1 1 1 0 0 1 1 0 0 1] parents\n",
      "[0 1 0 0 0 1 1 0 0 0] [1 0 0 0 1 1 1 1 1 0] parents\n",
      "[0 1 1 0 1 0 1 0 0 1] [0 0 0 1 1 1 1 1 1 0] parents\n",
      "[1 0 0 1 0 1 1 1 0 0] [1 1 0 1 0 1 0 0 0 1] parents\n",
      "[0 1 0 1 1 1 1 1 1 0] [0 1 0 0 0 0 1 0 0 1] parents\n",
      "[0 1 0 0 0 0 1 0 0 1] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[1 0 0 0 0 1 0 0 1 1] [1 1 0 1 1 1 0 0 0 0] parents\n",
      "[0 1 1 0 1 0 1 0 0 1] [1 0 1 1 0 0 1 0 1 1] parents\n",
      "[0 1 0 1 0 1 0 0 1 1] [0 0 0 0 0 0 1 1 0 0] parents\n",
      "[1 0 0 0 0 1 0 0 1 1] [1 1 1 0 0 1 0 1 0 0] parents\n",
      "[1 0 1 1 1 0 0 1 0 0] [1 1 0 0 1 1 1 0 1 1] parents\n",
      "[0 1 0 0 0 1 1 0 0 0] [1 1 1 1 0 0 0 1 0 1] parents\n",
      "[1 1 0 1 0 0 1 0 1 0] [0 1 1 0 1 0 1 0 0 1] parents\n",
      "[0 0 0 0 0 0 1 1 0 0] [0 1 0 1 0 1 0 0 1 1] parents\n",
      "[1 0 1 1 0 1 1 0 1 1] [0 1 1 1 0 1 1 0 0 1] parents\n",
      "[1 1 1 0 0 1 1 0 0 1] [1 1 1 0 0 1 1 1 1 1] parents\n",
      "[1 1 0 1 1 1 0 0 0 0] [1 1 0 0 1 1 1 0 1 1] parents\n",
      "Generation: 1, Max Fitness Score: 0.74733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 0 1 0 0 1] [0 1 0 0 0 0 1 1 1 0] parents\n",
      "[1 0 0 0 0 1 0 1 0 0] [0 1 0 1 1 0 0 1 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 1 1] [0 1 0 1 0 1 1 0 0 1] parents\n",
      "[1 0 1 1 0 1 0 0 1 1] [1 1 1 0 0 1 1 0 0 0] parents\n",
      "[1 0 1 1 1 0 1 0 1 1] [0 1 0 0 0 1 1 0 0 0] parents\n",
      "[0 1 0 1 1 0 0 1 0 0] [0 1 1 1 0 0 0 1 0 1] parents\n",
      "[1 0 1 1 0 1 0 0 1 1] [0 0 0 0 0 1 0 0 1 1] parents\n",
      "[0 1 1 0 1 0 1 0 1 1] [0 1 1 1 0 1 1 0 0 1] parents\n",
      "[1 1 0 1 0 0 1 0 0 1] [1 0 1 0 0 1 1 1 1 1] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [0 1 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 1 0 0 1 1 0 0 1] [1 1 1 0 0 0 1 0 0 0] parents\n",
      "[1 0 1 1 0 1 0 0 1 1] [1 1 1 0 0 1 1 1 1 1] parents\n",
      "[1 1 0 1 1 1 0 0 1 1] [1 1 0 1 0 0 1 0 0 1] parents\n",
      "[0 1 0 1 0 0 1 1 0 0] [1 1 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 0 1 0 1 1 0 0 1] [1 1 1 0 0 1 1 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 1 1] [1 1 0 1 0 1 1 0 0 1] parents\n",
      "[0 1 0 1 1 0 0 1 0 0] [0 1 1 0 1 0 1 1 1 0] parents\n",
      "[0 1 0 1 1 1 1 0 0 1] [1 1 1 0 1 1 1 1 1 0] parents\n",
      "[0 1 1 1 0 1 1 0 0 1] [1 0 0 0 0 0 1 1 0 1] parents\n",
      "[1 0 0 0 0 1 1 0 0 0] [1 1 1 1 0 1 1 0 0 1] parents\n",
      "[1 1 0 1 0 1 0 1 0 0] [0 1 0 0 0 0 1 1 1 0] parents\n",
      "[0 1 0 1 0 0 1 1 0 0] [1 1 1 0 0 1 1 0 0 1] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [1 1 0 1 0 1 0 1 0 0] parents\n",
      "[0 1 0 1 1 0 0 1 0 0] [0 1 0 1 0 1 1 0 0 1] parents\n",
      "[1 0 1 1 0 1 0 0 1 1] [1 0 0 0 0 0 1 1 0 1] parents\n",
      "Generation: 2, Max Fitness Score: 0.73641\n",
      "[1 0 1 1 0 1 1 1 1 1] [1 1 0 1 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 1 0 0 0] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[1 0 1 1 0 1 1 1 1 1] [1 1 0 1 0 1 0 0 1 1] parents\n",
      "[1 0 1 1 0 1 0 0 1 0] [1 1 1 0 0 1 0 0 1 1] parents\n",
      "[1 1 1 0 0 1 0 0 0 1] [1 1 0 1 0 1 1 0 1 1] parents\n",
      "[1 1 1 1 0 1 1 0 0 0] [1 0 0 0 0 1 0 0 1 1] parents\n",
      "[1 1 1 0 0 0 1 0 0 1] [0 1 1 0 1 1 1 1 1 0] parents\n",
      "[1 1 0 1 0 0 1 1 1 1] [1 1 1 0 0 0 1 0 0 1] parents\n",
      "[0 1 1 1 1 0 1 0 1 1] [1 0 1 1 0 1 0 0 1 0] parents\n",
      "[1 0 0 0 0 0 1 1 0 1] [1 1 1 0 0 1 0 0 0 1] parents\n",
      "[0 1 1 0 0 1 1 0 0 1] [1 1 1 1 0 1 1 0 0 0] parents\n",
      "[1 1 0 1 1 1 1 0 0 1] [0 1 0 1 0 0 1 1 0 1] parents\n",
      "[0 1 1 0 1 0 0 1 0 0] [0 1 1 1 0 1 1 0 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 0] [1 1 0 0 0 1 1 0 0 0] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[1 1 0 0 0 1 1 0 0 0] [0 1 1 0 0 1 0 0 1 1] parents\n",
      "[1 1 0 1 0 1 1 0 1 1] [1 0 1 1 0 1 1 1 1 1] parents\n",
      "[0 1 1 0 0 1 1 0 0 0] [1 0 0 0 0 1 0 0 1 1] parents\n",
      "[1 0 0 0 0 0 1 1 0 1] [0 1 0 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 1 0 0 0 1 0 0] [0 1 1 0 1 1 1 1 1 0] parents\n",
      "[0 1 0 0 0 1 1 1 0 0] [0 1 1 0 1 1 1 1 1 0] parents\n",
      "[0 1 0 0 0 1 0 1 0 0] [0 1 0 1 1 0 1 1 1 0] parents\n",
      "[0 1 1 0 0 1 0 0 1 1] [1 0 1 1 0 1 1 0 0 1] parents\n",
      "[1 0 0 1 0 1 1 0 0 1] [0 1 0 0 0 1 1 1 0 0] parents\n",
      "[0 0 1 1 1 0 1 0 1 1] [0 1 0 1 1 0 1 1 1 0] parents\n",
      "Generation: 3, Max Fitness Score: 0.74464\n",
      "[0 1 1 0 1 1 1 1 0 0] [1 1 0 0 0 1 1 0 0 0] parents\n",
      "[0 1 0 0 0 1 1 1 0 1] [0 1 1 1 1 0 1 0 1 0] parents\n",
      "[0 1 0 0 0 1 0 1 0 0] [1 1 0 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 0 0 1 1 0 0 0] [1 1 0 1 0 1 1 1 1 1] parents\n",
      "[1 1 1 1 0 1 0 0 1 1] [0 0 1 0 0 1 0 0 1 1] parents\n",
      "[1 1 1 1 0 1 0 0 1 1] [1 1 1 0 0 1 1 0 0 1] parents\n",
      "[1 1 1 0 0 1 1 0 0 1] [0 1 0 0 0 1 1 1 1 0] parents\n",
      "[1 1 0 0 0 1 0 0 1 1] [0 1 0 0 0 1 1 1 0 1] parents\n",
      "[0 1 1 0 0 1 0 0 0 1] [1 0 1 1 0 1 0 0 1 1] parents\n",
      "[0 1 0 0 0 1 0 1 0 0] [1 1 0 0 0 1 0 0 1 1] parents\n",
      "[0 1 0 0 0 1 1 1 1 0] [1 1 1 0 0 1 0 1 0 1] parents\n",
      "[0 1 1 0 1 0 0 1 0 0] [1 1 1 0 0 1 1 1 0 0] parents\n",
      "[0 1 0 0 0 1 0 1 0 0] [0 1 0 0 0 1 1 1 0 1] parents\n",
      "[0 1 1 1 1 0 1 0 1 0] [0 1 1 1 1 0 1 0 1 0] parents\n",
      "[0 1 1 0 1 1 1 1 0 0] [0 1 0 1 0 1 1 0 0 0] parents\n",
      "[0 1 1 0 1 1 1 0 0 1] [0 1 1 1 0 0 0 1 0 0] parents\n",
      "[0 1 1 1 0 0 0 1 0 0] [0 1 1 1 0 1 1 0 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 0] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[0 1 1 0 0 1 1 0 0 0] [1 1 1 0 0 1 0 1 0 1] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [1 1 0 1 0 1 1 1 0 1] parents\n",
      "[0 0 1 0 0 1 0 0 1 1] [1 1 0 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 0 0 1 0 1 0 0] [1 1 1 0 0 1 1 0 0 1] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [0 1 1 0 1 1 1 1 0 0] parents\n",
      "[0 1 0 0 0 1 0 1 0 0] [1 0 1 1 0 1 0 0 1 1] parents\n",
      "[1 1 1 1 0 0 1 1 1 1] [1 1 0 1 0 0 1 1 0 1] parents\n",
      "Generation: 4, Max Fitness Score: 0.73782\n",
      "[1 1 1 0 0 1 0 0 1 1] [0 1 1 1 1 0 1 0 1 0] parents\n",
      "[0 1 1 1 0 1 1 1 0 1] [1 1 0 0 0 1 0 1 0 0] parents\n",
      "[1 1 0 1 0 1 1 0 1 0] [0 1 1 0 0 1 1 0 0 1] parents\n",
      "[0 1 1 1 0 0 0 1 0 1] [0 1 1 1 0 1 0 0 1 1] parents\n",
      "[0 1 1 1 0 1 0 1 0 0] [0 1 1 0 1 1 1 1 0 0] parents\n",
      "[1 1 0 1 0 0 1 1 0 1] [1 1 0 0 0 1 0 1 0 0] parents\n",
      "[0 0 1 0 0 1 0 0 0 0] [1 1 1 0 0 1 0 0 1 1] parents\n",
      "[1 1 1 1 0 1 1 0 0 1] [0 1 0 1 0 1 1 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 1 0 0] [0 1 1 0 0 1 1 0 0 1] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [0 1 1 0 1 1 1 0 0 0] parents\n",
      "[0 1 1 0 0 1 1 1 0 0] [1 0 1 0 0 1 0 1 0 0] parents\n",
      "[1 1 0 0 0 1 0 1 0 0] [1 1 1 0 0 1 0 0 1 1] parents\n",
      "[1 1 0 1 0 1 1 0 1 0] [0 1 0 1 0 1 0 0 1 1] parents\n",
      "[1 1 1 0 0 1 0 0 1 1] [0 1 0 0 0 1 0 1 0 0] parents\n",
      "[1 1 0 1 0 1 1 0 1 0] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 1 1] [0 1 1 1 0 1 1 0 0 0] parents\n",
      "[0 1 1 1 0 1 1 1 0 1] [1 1 0 0 0 1 1 1 0 0] parents\n",
      "[1 1 0 0 0 1 0 1 0 0] [1 1 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 1 0 1 1 1 1 0 0] [0 1 1 0 1 1 1 1 0 0] parents\n",
      "[0 1 1 1 1 0 1 1 0 1] [1 1 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 0 0 0 1 0 0 1 1] [1 1 0 0 0 1 0 1 0 0] parents\n",
      "[1 1 1 0 0 1 1 1 1 0] [0 1 1 1 0 0 0 1 0 1] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[0 1 1 0 0 1 1 1 0 0] [0 1 0 1 0 1 0 0 1 1] parents\n",
      "[1 1 0 0 0 1 1 1 0 0] [0 1 1 0 1 1 1 1 0 0] parents\n",
      "Generation: 5, Max Fitness Score: 0.74896\n",
      "[1 1 0 0 0 1 1 1 0 1] [0 1 0 0 0 1 0 0 1 1] parents\n",
      "[1 1 1 1 0 1 0 1 0 0] [0 1 0 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [0 1 1 1 0 1 0 0 1 1] parents\n",
      "[0 1 0 1 0 1 0 0 1 0] [1 1 1 0 0 1 0 0 1 0] parents\n",
      "[0 1 1 0 0 1 1 0 0 0] [0 1 1 1 0 0 1 1 0 1] parents\n",
      "[0 1 1 0 0 1 1 0 0 0] [0 1 1 1 0 1 1 1 0 0] parents\n",
      "[1 1 0 0 0 0 0 0 1 1] [1 1 1 1 0 1 1 1 0 1] parents\n",
      "[1 1 0 1 0 0 1 1 0 0] [0 1 0 1 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 1 1] [1 1 0 1 0 1 1 0 0 0] parents\n",
      "[0 1 1 0 1 1 1 1 0 0] [1 1 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 1 1 0 0 1 1 0 1] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[0 1 1 0 1 1 1 1 0 0] [0 1 0 1 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 0 1 1] [0 1 0 1 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 1 0 0 1] [0 1 1 0 0 1 1 0 1 0] parents\n",
      "[0 1 1 0 0 1 1 0 0 0] [0 0 1 0 0 1 0 0 1 1] parents\n",
      "[0 1 1 0 0 1 1 0 1 0] [0 1 1 1 0 1 0 0 1 1] parents\n",
      "[0 1 1 0 0 1 1 1 1 0] [1 0 1 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 0 0 1 1 0 0 0] [0 1 1 0 0 1 1 1 1 0] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [1 1 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 1 0 0 1 1 1 0 0] [0 1 1 0 1 1 1 1 0 1] parents\n",
      "[0 1 1 0 1 1 1 1 0 1] [0 1 1 0 0 1 1 1 1 1] parents\n",
      "[1 1 0 1 0 0 1 1 0 0] [1 1 1 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 1 0 1 0 1 0 0] [0 1 1 0 1 1 1 0 0 0] parents\n",
      "[1 1 1 1 0 1 0 1 0 0] [1 1 0 1 0 1 1 0 1 1] parents\n",
      "[0 1 1 1 0 0 1 1 0 1] [1 1 0 1 0 1 1 0 0 0] parents\n",
      "Generation: 6, Max Fitness Score: 0.7524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 1 0 1 0 0] [1 1 1 1 0 1 0 0 1 1] parents\n",
      "[0 1 1 0 0 1 0 1 0 0] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[1 1 0 1 0 1 1 0 1 1] [0 1 1 0 1 1 1 0 0 1] parents\n",
      "[0 1 1 1 0 1 0 0 0 0] [1 1 0 1 0 1 1 0 1 1] parents\n",
      "[0 1 0 1 0 1 0 0 1 0] [1 1 1 1 0 1 0 1 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 1 1] [0 1 1 1 0 1 1 1 0 0] parents\n",
      "[0 1 1 0 1 1 1 1 0 0] [0 1 1 1 0 1 0 0 1 0] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [1 1 1 1 0 0 1 1 0 1] parents\n",
      "[0 1 1 0 0 1 1 1 1 0] [1 1 1 1 0 1 0 1 0 0] parents\n",
      "[1 1 1 0 0 1 0 1 0 0] [0 1 1 0 1 1 1 1 1 1] parents\n",
      "[1 1 0 1 0 0 1 1 0 0] [0 1 0 1 0 1 0 0 1 0] parents\n",
      "[0 1 1 0 0 1 0 1 0 0] [0 0 0 0 0 1 1 1 0 1] parents\n",
      "[0 1 0 1 0 1 1 0 0 0] [1 1 0 1 0 0 1 1 0 0] parents\n",
      "[1 1 1 1 0 1 0 0 0 0] [1 1 1 1 0 0 0 0 1 1] parents\n",
      "[0 1 1 1 1 0 1 1 0 1] [1 1 1 1 0 1 1 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 1 0 0] [1 1 1 1 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [0 1 0 1 0 1 1 0 0 0] parents\n",
      "[1 1 1 1 0 0 0 0 1 1] [0 1 1 1 0 1 1 0 0 0] parents\n",
      "[1 1 0 0 0 1 1 1 0 1] [1 1 1 1 0 1 0 1 0 0] parents\n",
      "[0 1 1 0 0 1 1 1 0 0] [1 1 1 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 0 1 1 1 1 0 1] [1 1 1 1 0 1 0 1 0 0] parents\n",
      "[0 1 0 1 0 1 0 0 1 0] [0 1 1 1 0 1 0 0 1 0] parents\n",
      "[1 1 1 0 0 1 0 0 1 0] [1 1 1 1 0 0 1 1 0 1] parents\n",
      "[0 1 1 1 0 1 0 0 1 1] [1 1 1 1 0 1 0 0 1 1] parents\n",
      "[0 1 0 1 0 1 1 0 0 0] [0 1 1 0 0 1 1 0 0 1] parents\n",
      "Generation: 7, Max Fitness Score: 0.74752\n",
      "[1 1 1 1 0 1 0 0 1 1] [1 0 0 1 0 1 0 0 0 0] parents\n",
      "[1 0 0 1 0 1 0 0 0 0] [1 1 1 1 0 1 0 0 1 1] parents\n",
      "[1 1 1 0 1 1 0 0 0 1] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[0 1 0 1 0 0 0 1 0 0] [0 1 0 1 0 1 1 0 0 0] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [1 1 1 1 1 0 1 1 0 1] parents\n",
      "[1 1 0 0 0 1 1 1 0 1] [0 1 1 1 1 1 1 0 1 1] parents\n",
      "[1 1 1 1 0 1 0 0 1 1] [0 1 1 1 0 1 0 0 1 0] parents\n",
      "[0 1 1 0 0 1 0 1 0 0] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[1 1 0 1 1 1 0 0 1 0] [1 1 1 0 0 1 0 1 1 1] parents\n",
      "[1 1 1 1 0 0 1 1 0 1] [0 1 0 1 0 0 0 1 0 0] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [1 1 1 0 0 1 0 1 1 1] parents\n",
      "[1 1 1 0 1 1 0 0 0 1] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 0] [1 1 1 1 0 1 0 0 1 1] parents\n",
      "[1 1 1 0 0 1 0 0 1 0] [0 1 1 1 0 1 0 1 0 0] parents\n",
      "[1 1 0 1 0 1 1 0 0 0] [1 1 1 0 0 1 0 0 1 0] parents\n",
      "[0 1 1 1 0 1 1 0 0 1] [0 1 0 1 0 0 0 1 0 0] parents\n",
      "[0 1 1 0 0 1 0 1 0 0] [0 1 1 1 0 1 1 0 0 1] parents\n",
      "[1 1 1 1 0 1 0 0 0 0] [0 1 0 1 0 1 1 0 1 1] parents\n",
      "[1 1 0 1 0 0 1 1 0 0] [1 1 1 1 0 0 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 1 1 0 0] [0 1 1 1 0 1 0 1 0 0] parents\n",
      "[1 1 1 1 1 0 1 1 0 1] [0 1 0 1 0 0 0 1 0 0] parents\n",
      "[0 1 1 1 0 1 0 1 0 0] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 1 0 1 0 1 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 0 0 0 0 1 0 1 0 0] [1 1 1 1 0 1 0 1 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 0] [0 1 0 0 0 1 1 0 0 1] parents\n",
      "Generation: 8, Max Fitness Score: 0.74417\n",
      "[0 1 1 0 1 1 0 0 0 1] [0 1 0 1 0 1 1 0 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 0] [0 1 1 1 1 1 1 0 1 1] parents\n",
      "[0 1 0 1 0 1 1 0 0 0] [1 1 1 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 0 1 1 0 0 0 1] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [1 0 0 1 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 0 1 0 1 0 1] [0 1 0 1 0 0 0 1 0 0] parents\n",
      "[1 1 0 1 0 0 0 0 0 0] [0 1 1 0 1 1 0 0 0 1] parents\n",
      "[1 1 1 1 0 1 0 0 0 0] [0 1 0 1 0 1 1 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 0 1 0] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 1 0 0 1] [1 1 1 1 0 1 0 0 1 1] parents\n",
      "[0 1 1 1 0 1 0 0 0 0] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[0 1 0 1 0 0 0 1 0 0] [0 1 1 1 0 0 1 1 0 1] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [1 1 0 0 0 1 1 0 0 1] parents\n",
      "[1 1 0 0 0 1 0 0 1 0] [0 0 0 0 0 1 0 1 0 0] parents\n",
      "[1 1 0 0 0 1 1 0 0 1] [1 1 1 1 0 1 0 0 0 0] parents\n",
      "[0 1 0 0 0 1 1 0 0 1] [1 0 1 1 0 1 0 0 1 0] parents\n",
      "[0 1 1 0 0 1 0 1 0 0] [0 0 0 0 0 1 0 1 0 0] parents\n",
      "[1 0 0 1 0 1 0 0 0 1] [1 1 1 1 0 1 1 0 0 0] parents\n",
      "[1 1 1 1 0 1 0 1 0 0] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[1 1 1 0 0 1 0 1 1 1] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 1 0] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 0] [0 1 1 1 0 1 0 0 1 1] parents\n",
      "[1 0 0 1 0 1 0 0 0 1] [1 1 1 1 0 1 0 0 1 1] parents\n",
      "[1 0 1 1 0 1 0 0 1 0] [1 1 1 0 0 1 0 1 0 0] parents\n",
      "Generation: 9, Max Fitness Score: 0.74194\n",
      "[0 1 0 1 0 1 1 0 1 1] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 1 0 0 1] [0 1 0 1 0 1 0 0 0 0] parents\n",
      "[1 0 1 1 0 1 0 1 0 0] [1 1 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 1 0 1 1 0 0 0 1] [0 0 1 1 0 1 0 0 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 1 1] [0 1 1 0 1 0 0 0 0 0] parents\n",
      "[1 0 1 1 0 1 0 1 0 0] [1 1 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 1 0 1 1 0 0 0 0] [1 1 1 0 0 1 1 0 0 1] parents\n",
      "[0 1 1 1 0 1 1 0 1 1] [0 1 1 1 0 1 1 0 1 1] parents\n",
      "[0 1 1 0 0 1 0 1 0 0] [0 1 0 0 0 1 0 0 1 0] parents\n",
      "[1 0 0 0 0 1 1 0 0 0] [1 1 0 0 0 1 0 0 0 0] parents\n",
      "[1 0 0 0 0 1 1 0 0 0] [0 1 0 0 0 1 0 0 1 0] parents\n",
      "[0 1 1 1 0 0 1 1 0 1] [1 0 1 1 0 1 1 0 0 1] parents\n",
      "[0 1 1 1 1 1 1 0 0 0] [1 1 0 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 0 0] [0 1 0 1 0 1 1 0 0 1] parents\n",
      "[0 1 0 0 0 1 0 0 1 0] [0 0 0 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 0 1 1 0 0 0 1] [0 1 0 1 0 1 1 0 1 1] parents\n",
      "[1 0 1 1 0 1 1 0 0 0] [1 1 0 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[1 1 1 0 0 1 0 1 1 1] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 0 0] [0 1 1 1 1 1 1 0 0 0] parents\n",
      "[1 0 0 0 0 1 1 0 0 0] [1 1 0 0 0 0 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 1 0 1 0 1 0 0] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 1 1 0 0 0 0] [0 1 0 1 0 1 1 0 0 1] parents\n",
      "[0 1 1 1 0 0 1 1 0 1] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "Generation: 10, Max Fitness Score: 0.73919\n",
      "[1 1 0 0 0 1 0 0 1 0] [0 1 1 1 0 1 0 1 0 0] parents\n",
      "[0 1 0 1 1 1 1 0 0 0] [1 1 0 0 0 1 1 0 0 0] parents\n",
      "[0 0 1 1 0 1 0 0 0 1] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 1 0 0] [1 1 0 0 0 1 1 0 0 1] parents\n",
      "[1 1 1 1 0 1 1 1 0 0] [0 1 0 1 0 1 1 0 0 1] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 1 0 1 1 0 0 0 0] parents\n",
      "[1 1 1 1 0 1 0 0 0 0] [0 1 1 1 0 1 1 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [1 1 1 0 0 1 0 1 0 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 1 0] parents\n",
      "[0 1 0 0 0 1 1 0 0 0] [1 1 1 1 0 1 1 1 0 0] parents\n",
      "[0 1 1 1 0 0 1 0 0 1] [1 1 0 0 0 1 0 0 1 0] parents\n",
      "[0 1 1 0 1 0 0 0 1 1] [0 1 1 0 0 1 0 0 1 0] parents\n",
      "[1 1 0 0 0 1 1 0 0 1] [1 1 0 0 0 1 1 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 1 1 0 1 1 0 1 1] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [0 1 1 0 1 0 0 0 1 1] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 1 0 1 1 0 0 0 1] parents\n",
      "[1 1 0 0 0 1 1 0 0 0] [1 1 0 0 0 1 1 0 0 1] parents\n",
      "[0 1 0 0 0 1 0 0 1 0] [1 0 1 1 1 1 0 1 0 1] parents\n",
      "[0 1 0 1 0 1 1 0 0 1] [0 1 1 0 1 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 1 1 0 1 0 1 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [1 0 0 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 1 0 0] [1 1 1 1 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 1 0 0] [1 1 0 0 0 1 1 0 0 1] parents\n",
      "[1 0 0 0 0 1 0 0 0 0] [0 0 1 1 0 1 0 0 0 1] parents\n",
      "[0 1 1 1 0 1 1 0 1 1] [0 1 1 0 0 1 0 1 0 0] parents\n",
      "Generation: 11, Max Fitness Score: 0.7471\n",
      "[1 1 1 0 0 1 0 1 0 0] [1 1 0 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 1 1 1 0 0 0] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 1 0 0 1] [0 1 1 0 0 1 0 1 1 1] parents\n",
      "[0 1 0 0 0 0 0 1 0 1] [0 1 1 1 0 1 1 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 1 1 1] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "[1 1 1 1 0 1 1 0 0 0] [0 1 0 1 1 1 1 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 1 0 0] [0 1 1 0 0 1 0 0 1 0] parents\n",
      "[0 1 1 0 0 1 0 1 1 1] [1 1 1 1 0 1 0 1 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 1 0] [1 1 1 0 0 1 0 0 0 1] parents\n",
      "[0 1 1 1 0 1 0 0 0 0] [0 0 1 1 0 1 0 0 0 1] parents\n",
      "[0 1 0 0 0 1 1 1 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 1 0 0] [1 1 1 1 0 1 1 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 1 0] [0 1 0 1 0 1 1 1 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 1] [1 1 0 0 0 1 0 0 0 1] parents\n",
      "[1 1 0 0 0 1 0 1 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 1 1 0 1 0 0 1 0] parents\n",
      "[1 1 0 0 0 1 0 0 0 0] [0 1 1 0 1 1 0 0 0 0] parents\n",
      "[0 1 1 0 0 1 0 0 1 0] [1 1 1 1 0 1 1 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 0 0] [1 1 0 0 0 1 1 0 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 1] [1 1 0 0 0 1 1 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 0 0 0 1 1 1 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [1 1 1 1 0 1 0 1 0 0] parents\n",
      "[1 1 0 0 0 1 0 1 0 0] [1 1 0 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 1 0 1 1 0 0 1] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 1 0 0 0 1 0] [0 1 0 1 1 1 1 0 0 0] parents\n",
      "Generation: 12, Max Fitness Score: 0.74919\n",
      "[0 0 1 1 0 1 0 0 0 0] [1 1 0 0 0 1 0 0 0 1] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [0 0 1 1 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 0 0 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 1 1 0] [1 1 0 0 0 1 0 0 0 1] parents\n",
      "[0 1 1 1 0 1 1 1 0 0] [0 1 1 1 0 1 0 0 1 1] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [1 1 1 1 0 1 0 1 0 0] parents\n",
      "[1 1 1 1 0 1 0 0 1 0] [1 1 1 0 0 1 1 0 0 0] parents\n",
      "[0 1 0 0 0 0 1 0 0 0] [0 1 1 0 0 1 1 0 0 1] parents\n",
      "[0 1 1 0 0 1 0 0 0 1] [1 1 0 0 0 1 0 1 1 1] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [1 1 0 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 1 0 0 0 1 0] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 1 0 1] [0 1 1 0 1 0 0 0 1 0] parents\n",
      "[0 1 1 0 1 0 0 0 1 0] [1 1 1 1 0 1 1 1 1 1] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [1 1 1 0 0 1 0 1 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 0 0 0 1 0 1 0 0] parents\n",
      "[0 1 0 1 1 1 1 0 0 0] [0 1 1 1 0 1 0 0 1 1] parents\n",
      "[0 0 1 1 0 1 0 0 0 0] [0 0 1 1 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 1 1 0 0 0 0] [1 1 0 0 0 1 0 0 0 1] parents\n",
      "[0 1 0 1 1 1 1 0 0 0] [0 1 1 0 0 1 0 0 0 1] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 1 0 0] [1 1 1 0 0 1 0 1 0 0] parents\n",
      "[1 1 1 0 0 0 0 0 0 0] [0 1 0 1 1 1 1 0 0 0] parents\n",
      "[0 1 0 1 0 1 0 0 0 0] [0 1 1 0 0 1 1 0 0 1] parents\n",
      "[0 1 1 1 0 1 0 0 0 1] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 1 0 1] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "Generation: 13, Max Fitness Score: 0.74761\n",
      "[0 1 1 0 0 1 0 0 0 0] [1 1 1 1 0 1 0 1 0 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [0 1 0 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 1 1 1 1 1 1] [0 1 1 0 1 1 1 1 1 1] parents\n",
      "[0 1 1 0 1 1 1 1 1 1] [0 1 0 0 1 1 1 0 0 1] parents\n",
      "[0 0 1 0 0 1 0 0 0 1] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 1 0 0] [0 1 1 1 0 1 0 1 0 1] parents\n",
      "[0 1 1 1 1 1 0 0 0 1] [0 1 1 0 0 1 0 1 1 1] parents\n",
      "[1 1 0 0 0 1 0 0 0 1] [0 1 1 0 0 1 0 1 1 1] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [1 1 1 1 0 0 0 0 1 0] parents\n",
      "[0 1 1 1 0 1 0 1 0 1] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 1 0] [1 1 0 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 1 0] [0 1 1 0 0 1 0 1 1 1] parents\n",
      "[1 1 1 0 0 1 0 1 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 1 0 1 1 0 0 0] [0 1 1 1 0 1 0 0 1 0] parents\n",
      "[1 1 1 0 0 0 0 0 0 0] [0 1 1 0 0 1 0 1 1 1] parents\n",
      "[0 1 0 1 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [1 1 1 0 0 1 1 0 0 0] parents\n",
      "[1 1 1 1 0 1 0 0 1 0] [0 1 1 1 0 1 1 1 0 0] parents\n",
      "[0 1 1 1 0 1 1 1 0 0] [0 1 1 1 0 1 1 1 0 0] parents\n",
      "[1 1 0 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 1 1 0 1 0 0 1 0] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 0 0 0] [0 1 1 1 0 1 0 0 1 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [0 1 1 1 0 1 1 1 0 0] parents\n",
      "Generation: 14, Max Fitness Score: 0.73526\n",
      "[0 1 1 0 0 1 0 0 0 0] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 1] [0 1 1 1 0 1 0 0 1 0] parents\n",
      "[0 1 1 1 0 1 1 1 0 0] [1 1 1 0 0 1 0 0 1 0] parents\n",
      "[1 1 1 0 0 1 0 1 1 1] [0 1 0 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 0 1] parents\n",
      "[0 1 1 1 0 1 1 0 0 0] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 0 0] [0 1 1 0 1 1 1 1 1 1] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 1 0] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [0 1 0 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 1] [1 1 1 0 0 1 0 1 1 1] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [1 1 0 0 0 1 0 1 0 1] parents\n",
      "[0 1 0 1 0 1 0 0 0 0] [0 1 0 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 1 0] [0 1 1 1 0 1 0 1 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 0 1] [0 1 1 0 1 1 1 1 1 1] parents\n",
      "[0 1 1 1 0 1 0 0 1 1] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 0 1 0] [1 1 1 1 0 1 0 0 1 0] parents\n",
      "[1 1 1 1 0 1 1 1 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [1 1 0 0 0 1 0 0 1 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [1 1 0 0 0 1 0 0 1 0] parents\n",
      "[0 1 1 0 0 1 0 0 1 0] [0 1 1 1 0 1 1 0 0 0] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [1 1 1 0 0 1 0 1 1 1] parents\n",
      "[0 1 1 1 0 1 1 1 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 1 0 1] [1 1 0 0 0 1 0 0 1 0] parents\n",
      "[1 1 1 0 0 1 0 0 1 0] [0 1 0 0 0 1 0 0 0 0] parents\n",
      "Generation: 15, Max Fitness Score: 0.73387\n",
      "[0 1 0 0 0 1 0 0 0 0] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [0 1 1 0 1 1 1 1 1 1] parents\n",
      "[1 1 1 1 0 0 0 0 1 0] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 1 1 1] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 0 1 0] [0 1 0 1 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 1 0 1] [1 1 0 0 0 1 0 0 1 0] parents\n",
      "[0 1 0 0 0 1 0 0 0 1] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 1 1 1] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 1 1 1] [1 1 0 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 0 1 0] [0 1 1 1 0 1 1 0 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 0 0 1 0] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 1 0 1] [0 1 1 1 0 1 1 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [0 1 0 0 0 1 0 1 0 1] parents\n",
      "[0 1 1 1 0 1 1 0 1 0] [0 1 1 1 0 1 1 1 1 0] parents\n",
      "[0 1 1 0 0 1 0 0 1 1] [0 1 1 1 0 1 1 1 0 0] parents\n",
      "[1 1 1 0 0 1 1 0 0 0] [0 1 0 0 0 1 0 1 1 1] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 1 1 1 1 1 1] [1 1 1 0 0 1 1 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 0 0 0] [0 1 1 1 0 1 0 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [1 1 1 0 0 1 1 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 0 1 0] [0 1 1 1 0 1 1 1 1 1] parents\n",
      "[0 1 0 0 0 1 0 0 0 1] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "Generation: 16, Max Fitness Score: 0.74967\n",
      "[0 1 0 1 0 1 1 1 0 0] [1 1 0 0 0 1 0 1 0 1] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [1 1 0 0 0 1 0 1 0 1] parents\n",
      "[0 1 1 1 0 1 1 1 1 1] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [0 1 1 1 0 1 1 0 1 0] parents\n",
      "[1 1 0 1 0 1 0 0 0 0] [1 1 1 1 0 1 0 0 1 0] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [1 1 0 0 0 1 0 1 0 1] parents\n",
      "[1 1 1 0 0 0 0 1 1 1] [0 1 1 1 0 1 1 1 1 0] parents\n",
      "[1 1 1 0 1 1 1 1 1 1] [0 1 1 1 0 0 0 0 1 0] parents\n",
      "[1 1 0 0 0 1 0 0 0 0] [1 1 0 1 0 1 1 1 1 1] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [1 1 1 1 0 1 0 0 1 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [0 1 0 0 0 1 0 1 0 0] parents\n",
      "[1 1 0 0 0 1 0 1 0 1] [1 1 1 0 0 1 0 1 1 1] parents\n",
      "[0 1 1 1 0 0 0 0 1 0] [0 1 0 1 0 1 1 1 0 0] parents\n",
      "[1 1 1 0 0 1 0 0 0 0] [1 1 1 0 0 1 0 0 0 0] parents\n",
      "[1 1 0 0 0 1 0 0 0 0] [0 1 0 0 0 1 0 1 1 0] parents\n",
      "[1 1 1 1 0 1 0 0 1 0] [0 1 0 0 0 1 0 0 0 0] parents\n",
      "[1 1 1 0 0 0 0 1 1 1] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [1 1 0 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 1 0 1 1 1 1 0] [1 1 1 0 0 0 0 1 1 1] parents\n",
      "[0 1 0 0 0 1 0 0 0 0] [0 1 1 0 0 1 0 0 0 0] parents\n",
      "[0 1 1 0 0 1 0 0 0 0] [0 1 1 1 0 1 1 0 1 0] parents\n",
      "[1 1 1 0 1 1 1 1 1 1] [0 1 1 0 0 1 0 0 0 1] parents\n",
      "[0 1 1 0 0 1 1 0 0 0] [0 1 1 0 0 1 1 0 0 0] parents\n",
      "[0 1 0 1 0 1 0 0 1 0] [0 1 1 1 0 1 1 0 0 1] parents\n",
      "[1 1 0 0 0 1 0 0 0 0] [0 1 1 1 0 0 0 0 1 0] parents\n",
      "Generation: 17, Max Fitness Score: 0.74846\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23/798983823.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mdf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitness_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_23/798983823.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dataframe_path, number_of_generation, mutation_rate, n_individual, max_features)\u001b[0m\n\u001b[1;32m     43\u001b[0m                                     \u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                 )\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mfitness_score\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fitness_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mnew_generation_population\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_generation_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitness_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23/1562035718.py\u001b[0m in \u001b[0;36mget_fitness_score\u001b[0;34m(self, regression, verbose)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_nparray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23/1562035718.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_X, train_y, input_dims)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \"\"\"\n\u001b[1;32m     67\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mcol_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn\n",
    "#from train_preprocessing import *\n",
    "#from neural_net import *\n",
    "#from generate_population import *\n",
    "#from fitness_score import *\n",
    "\n",
    "def main(dataframe_path, number_of_generation=10, mutation_rate=0.1, n_individual=100, max_features=25): \n",
    "    \"\"\"\n",
    "        This method is the combines all the genetic algo pieces into one, and evolve over generation,\n",
    "        to provide a fittest population.\n",
    "        Params:\n",
    "            dataframe_path         : Path for the csv file that contains the dataset.\n",
    "            number_of_generation   : Number of generation to evolve.\n",
    "            mutation_rate          : Mutation Rate, decides whether to mutate the children or not, based on probability.\n",
    "            n_individual           : Number of individuals, needed to be created in a population, if the value is 0, \n",
    "                                     it will create a power(len(fearures), 2)\n",
    "            max_features           : Subset size, if value is 0, then the subset size will be len(features).\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe = pd.read_csv(dataframe_path)\n",
    "    dataframe = preprocess_dataframe(dataframe)\n",
    "    \n",
    "    train_X, train_y, test_X, test_y = get_training_testing_data(dataframe, \"Churn\", 0.8)\n",
    "    print(\"Before Resampling\", train_X.shape)\n",
    "\n",
    "    train_X, train_y = handle_imbalance(train_X, train_y)\n",
    "    print(\"After Resampling\", train_X.shape)\n",
    "\n",
    "    num_cols = len(train_X.columns)\n",
    "    generator = GenPopulation()\n",
    "    population = generator.generate(num_cols, n_individual, max_features)\n",
    "    \n",
    "    for i in range(number_of_generation): \n",
    "        print(f\"Generation: {i}\")\n",
    "        fitness_function = FitnessFunction(\n",
    "                                    population,\n",
    "                                    train_X,\n",
    "                                    train_y,\n",
    "                                    test_X,\n",
    "                                    test_y,\n",
    "                                    train_X.columns,\n",
    "                                    \"acc\"\n",
    "                                )\n",
    "        fitness_scores , prediction_scores = fitness_function.get_fitness_score(regression=False, verbose=False)\n",
    "        \n",
    "        new_generation_population = get_next_generation_population(population, fitness_scores, mutation_rate)\n",
    "        population = new_generation_population\n",
    "        print(f\"Generation: {i}, Max Prediction Score: {max(prediction_scores)}\")\n",
    "            \n",
    "    return population, fitness_scores, prediction_scores\n",
    "\n",
    "df_path = \"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "pop, fitness_score, _ = main(df_path, 20, 0.1, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"shilas\"\n",
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sh'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ilas'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
